version: '3.8'

services:
  hunyuanworld-voyager:
    # Usar imagem base e instalar tudo via init container
    image: nvidia/cuda:12.4-devel-ubuntu22.04
    container_name: hunyuanworld-voyager
    restart: unless-stopped
    
    # Script de inicializa√ß√£o inline
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        set -e
        echo "üöÄ Starting HunyuanWorld-Voyager..."
        
        # Update system and install dependencies
        export DEBIAN_FRONTEND=noninteractive
        apt-get update
        apt-get install -y python3.11 python3.11-dev python3-pip git wget curl ffmpeg \
                          libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1
        
        # Configure Python
        update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
        update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1
        python3 -m pip install --upgrade pip
        
        # Clone repository if it doesn't exist
        if [ ! -d "/app/.git" ]; then
            echo "üì¶ Cloning repository..."
            cd /
            git clone https://github.com/dmax101/HunyuanWorld-Voyager.git app
            cd /app
        else
            echo "üìÅ Repository already exists, updating..."
            cd /app
            git pull
        fi
        
        # Install PyTorch CUDA
        echo "üîß Installing PyTorch..."
        pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124
        
        # Install project dependencies
        echo "üìö Installing dependencies..."
        pip install -r requirements.txt
        pip install transformers==4.39.3 flash-attn xfuser==0.4.2 nvidia-cublas-cu12==12.4.5.8 scipy==1.11.4
        
        # Install additional dependencies
        pip install --no-deps git+https://github.com/microsoft/MoGe.git
        pip install git+https://github.com/EasternJournalist/utils3d.git@c5daf6f6c244d251f252102d09e9b7bcef791a38
        
        # Create necessary directories
        mkdir -p /app/ckpts /app/examples /app/results /app/temp /app/temp_images
        
        # Configure environment variables
        export CUDA_HOME=/usr/local/cuda
        export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$$LD_LIBRARY_PATH
        export PATH=/usr/local/cuda/bin:$$PATH
        
        # Check GPU
        echo "üéÆ Checking GPU..."
        nvidia-smi || echo "‚ö†Ô∏è  GPU not detected"
        
        # Check if models exist
        if [ ! -f "/app/ckpts/config.json" ]; then
            echo "‚ö†Ô∏è  Models not found in /app/ckpts/"
            echo "üì• To download models, run:"
            echo "   docker exec -it hunyuanworld-voyager bash"
            echo "   cd /app/ckpts"
            echo "   pip install huggingface_hub[cli]"
            echo "   huggingface-cli download tencent/HunyuanWorld-Voyager --local-dir ./"
        fi
        
        echo "‚úÖ Configuration completed!"
        echo "üåê Starting web interface at http://localhost:3500"
        echo "üìñ For complete instructions, see: https://github.com/dmax101/HunyuanWorld-Voyager"
        
        # Iniciar aplica√ß√£o
        cd /app
        python3 app.py
    
    # Configura√ß√£o de GPU - Requere NVIDIA Container Toolkit
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Portas
    ports:
      - "3500:8080"  # Interface web Gradio
    
    # Volumes persistentes
    volumes:
      # C√≥digo fonte persistente (para n√£o refazer clone)
      - ./app:/app:rw
      
      # Modelos pr√©-treinados (download separado necess√°rio)
      - ./data/ckpts:/app/ckpts:rw
      
      # Exemplos e entradas
      - ./data/examples:/app/examples:rw
      
      # Resultados gerados
      - ./data/results:/app/results:rw
      
      # Diret√≥rio tempor√°rio
      - ./data/temp:/app/temp:rw
      
      # Imagens tempor√°rias para upload
      - ./data/temp_images:/app/temp_images:rw
      
      # Cache de modelos HuggingFace (opcional)
      - ./data/huggingface_cache:/root/.cache/huggingface:rw
      
      # Cache pip para acelerar reinstala√ß√µes
      - ./data/pip_cache:/root/.cache/pip:rw
    
    # Vari√°veis de ambiente
    environment:
      # CUDA
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=all
      
      # Python
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      
      # HuggingFace
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers
      
      # Configura√ß√µes do modelo
      - ALLOW_RESIZE_FOR_SP=1
      
      # Interface web
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=8080
    
    # Configura√ß√µes de recursos
    # IMPORTANTE: Este modelo requer m√≠nimo 60GB de VRAM
    shm_size: 8gb
    
    # Configura√ß√µes de rede
    networks:
      - voyager-network
    
    # Healthcheck
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080 || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 300s  # 5 minutos para primeira inicializa√ß√£o
    
    # Comando padr√£o (pode ser sobrescrito)
    # command j√° definido no entrypoint acima

networks:
  voyager-network:
    driver: bridge

# Configura√ß√£o de volumes nomeados (opcional)
volumes:
  voyager_models:
    driver: local
  voyager_results:
    driver: local